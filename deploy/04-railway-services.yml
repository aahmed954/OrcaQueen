# Railway Pro Cloud Services - Overflow and High-Availability
# Deploy to Railway Cloud (32GB RAM / 32 vCPU available)
# $20/month includes all usage - perfect for burst capacity

version: '3.8'

services:
  # Railway Service 1: Backup vLLM Inference (High Availability)
  railway-vllm-backup:
    image: vllm/vllm-openai:latest
    container_name: railway-vllm-backup
    restart: always
    environment:
      # Railway auto-injects PORT env var
      PORT: 8000
      CUDA_VISIBLE_DEVICES: ""  # CPU mode on Railway (no GPU)
      VLLM_WORKER_MULTIPROC_METHOD: spawn
      VLLM_CPU_MODE: 1  # Enable CPU inference
      VLLM_ENGINE_ITERATION_TIMEOUT_S: 3600
      VLLM_LOG_LEVEL: INFO
      RAILWAY_SERVICE_NAME: vllm-backup
    command: [
      "--model", "microsoft/Phi-3-mini-4k-instruct",  # Smaller model for CPU
      "--served-model-name", "phi-3-mini",
      "--host", "0.0.0.0",
      "--port", "${PORT:-8000}",
      "--dtype", "float32",  # CPU compatible
      "--max-model-len", "4096",
      "--tensor-parallel-size", "1",
      "--device", "cpu"
    ]
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '16'
    labels:
      railway.app/service: vllm-backup
      railway.app/healthcheck-path: /health
      railway.app/healthcheck-timeout: 30

  # Railway Service 2: Additional LiteLLM Gateway (Load Balancing)
  railway-litellm-lb:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: railway-litellm-lb
    restart: always
    environment:
      PORT: 4000
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      DATABASE_URL: postgresql://postgres:${POSTGRES_PASSWORD}@oracle-postgres.railway.internal:5432/litellm
      REDIS_HOST: railway-redis.railway.internal
      REDIS_PORT: 6379
      STORE_MODEL_IN_DB: true
      LITELLM_MODE: PRODUCTION
      # Railway specific
      RAILWAY_SERVICE_NAME: litellm-lb
      # Model endpoints
      STARLORD_VLLM_URL: http://100.72.73.3:8000/v1
      THANOS_BACKUP_URL: http://100.122.12.54:8002/v1
      RAILWAY_VLLM_URL: http://railway-vllm-backup.railway.internal:8000/v1
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '4'
    labels:
      railway.app/service: litellm-lb
      railway.app/healthcheck-path: /health
      railway.app/domains: ai-swarm-gateway.up.railway.app

  # Railway Service 3: Redis Cache Cluster
  railway-redis:
    image: redis:7-alpine
    container_name: railway-redis
    restart: always
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --maxmemory 8gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - railway-redis-data:/data
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
    labels:
      railway.app/service: redis-cache
      railway.app/volume: railway-redis-data

  # Railway Service 4: Web Scraping & Research Worker
  railway-research-worker:
    build:
      context: ../services/research-worker
      dockerfile: Dockerfile
    container_name: railway-research-worker
    restart: always
    environment:
      PORT: 8002
      # API Keys
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      BRAVE_API_KEY: ${BRAVE_API_KEY}
      PERPLEXITY_API_KEY: ${PERPLEXITY_API_KEY}
      # Research config
      MAX_WORKERS: 8
      MAX_SEARCH_RESULTS: 20
      ENABLE_CACHING: true
      CACHE_TTL: 3600
      # Railway specific
      RAILWAY_SERVICE_NAME: research-worker
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '8'
    labels:
      railway.app/service: research-worker
      railway.app/healthcheck-path: /health
      railway.app/domains: research.ai-swarm.up.railway.app

  # Railway Service 5: Cost Analytics Dashboard
  railway-analytics:
    image: grafana/grafana:latest
    container_name: railway-analytics
    restart: always
    environment:
      PORT: 3000
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: redis-datasource,prometheus
      GF_SERVER_ROOT_URL: https://analytics.ai-swarm.up.railway.app
      RAILWAY_SERVICE_NAME: analytics
    volumes:
      - railway-grafana-data:/var/lib/grafana
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
    labels:
      railway.app/service: analytics
      railway.app/domains: analytics.ai-swarm.up.railway.app
      railway.app/volume: railway-grafana-data

volumes:
  railway-redis-data:
    driver: local
  railway-grafana-data:
    driver: local

# Railway Deployment Notes:
# 1. Each service gets its own Railway service for independent scaling
# 2. Railway provides automatic HTTPS endpoints
# 3. Internal networking via *.railway.internal domains
# 4. Auto-scaling based on CPU/memory usage
# 5. Zero-downtime deployments with health checks
# 6. Persistent volumes for data retention

# Cost Optimization:
# - Pro plan includes $20/month of usage
# - With 32GB RAM and 32 vCPU available
# - Perfect for burst capacity and overflow
# - Automatic sleep when not in use saves credits