# Oracle ARM Node - ARM64 Compatible Services Only
# Deploy to: 100.96.197.84
# CRITICAL: All images MUST be ARM64/aarch64 compatible

version: '3.8'

services:
  # PostgreSQL - ARM64 compatible
  postgres:
    image: arm64v8/postgres:15-alpine  # ARM64 specific image
    container_name: oracle-postgres
    restart: always
    user: "postgres:postgres"  # Non-root user
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: litellm
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./config/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U litellm"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID

  # Redis - ARM64 compatible
  redis:
    image: arm64v8/redis:7-alpine  # ARM64 specific image
    container_name: oracle-redis
    restart: always
    user: "redis:redis"  # Non-root user
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --protected-mode yes
      --port 6379
      --bind 0.0.0.0
    volumes:
      - redis_data:/data
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # Consul - Service Discovery (ARM64 compatible)
  consul:
    image: arm64v8/consul:latest  # ARM64 specific image
    container_name: oracle-consul
    restart: always
    ports:
      - "100.96.197.84:8500:8500"
    environment:
      CONSUL_BIND_INTERFACE: eth0
      CONSUL_CLIENT_INTERFACE: eth0
    command: agent -server -bootstrap -ui -client=0.0.0.0
    volumes:
      - consul_data:/consul/data
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true

  # HAProxy - Load Balancer (ARM64 compatible)
  haproxy:
    image: arm64v8/haproxy:2.8-alpine  # ARM64 specific image
    container_name: oracle-haproxy
    restart: always
    ports:
      - "100.96.197.84:80:80"
      - "100.96.197.84:443:443"
      - "100.96.197.84:8888:8888"  # Stats page
    volumes:
      - ./config/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./certs:/etc/ssl/certs:ro
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

    # LiteLLM Gateway - Latest ARM64 compatible version
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    platform: linux/arm64
    container_name: oracle-litellm
    restart: always
    user: "1000:1000"  # Non-root user
    ports:
      - "100.96.197.84:4000:4000"
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      DATABASE_URL: postgresql://litellm:${POSTGRES_PASSWORD}@postgres:5432/litellm
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      LITELLM_LOG_LEVEL: INFO
      LITELLM_CACHE: redis
      LITELLM_CACHE_PARAMS: '{"host": "redis", "port": 6379, "password": "${REDIS_PASSWORD}"}'
    volumes:
      - ./config/litellm.yaml:/app/config.yaml:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # Open WebUI - Latest ARM64 compatible version
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    platform: linux/arm64
    container_name: oracle-open-webui
    restart: always
    user: "1000:1000"  # Non-root user
    ports:
      - "100.96.197.84:3000:8080"
    environment:
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY}
      OPENAI_API_BASE_URL: http://localhost:4000/v1
      OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
      ENABLE_OLLAMA_API: false
      ENABLE_OPENAI_API: true
      ENABLE_SIGNUP: false
      ENABLE_COMMUNITY_SHARING: false
      WEBUI_AUTH: true
      WEBUI_AUTH_TRUSTED_EMAIL_HEADER:
      DEFAULT_MODELS: mixtral-8x7b
      DEFAULT_USER_ROLE: user
      ENABLE_ADMIN_EXPORT: true
      ADMIN_EMAIL: admin@ai-swarm.local
      JWT_EXPIRES_IN: 86400
      ENABLE_API_KEY: true
      ENABLE_API_KEY_ENDPOINT_RESTRICTIONS: true
      API_KEY_ALLOWED_ENDPOINTS: /api/v1/chat/completions,/api/v1/models
    volumes:
      - openwebui_data:/app/backend/data
    depends_on:
      litellm:
        condition: service_healthy
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # Grafana - Monitoring Dashboard (ARM64 compatible)
  grafana:
    image: grafana/grafana:latest  # Multi-arch image
    container_name: oracle-grafana
    restart: always
    user: "472:472"  # Grafana user
    ports:
      - "100.96.197.84:3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: redis-datasource,prometheus
      GF_SERVER_ROOT_URL: http://100.96.197.84:3001
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning:ro
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # Prometheus - Metrics Collection (ARM64 compatible)
  prometheus:
    image: prom/prometheus:latest  # Multi-arch image
    container_name: oracle-prometheus
    restart: always
    user: "nobody:nobody"  # Non-root user
    ports:
      - "100.96.197.84:9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/alert.rules.yml:/etc/prometheus/alert.rules.yml:ro
      - prometheus_data:/prometheus
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # AlertManager - Alert handling
  alertmanager:
    image: prom/alertmanager:latest  # Multi-arch
    container_name: oracle-alertmanager
    restart: always
    ports:
      - "100.96.197.84:9093:9093"
    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true

  # ELK Stack - Lightweight logging (Elasticsearch, Logstash, Kibana)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0  # Multi-arch
    container_name: oracle-elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false  # Disabled for single user
      - ES_JAVA_OPTS=-Xms512m -Xmx512m  # Lightweight
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "100.96.197.84:9200:9200"
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    container_name: oracle-logstash
    restart: always
    volumes:
      - ./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    ports:
      - "100.96.197.84:5044:5044"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - aiswarm

  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    container_name: oracle-kibana
    restart: always
    ports:
      - "100.96.197.84:5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      XPACK_SECURITY_ENABLED: false
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - aiswarm

  # Vault - Secrets Management (ARM64 compatible, Production Mode)
  vault:
    image: hashicorp/vault:latest  # Multi-arch image
    container_name: oracle-vault
    restart: always
    ports:
      - "100.96.197.84:8200:8200"
    command: ["server", "-config=/vault/config/config.hcl"]
    cap_add:
      - IPC_LOCK
    volumes:
      - vault_data:/vault/data
      - ./config/vault/config.hcl:/vault/config/config.hcl:ro
      - ./config/certs:/vault/tls:ro  # TLS certs for secure listener
    networks:
      - aiswarm
    security_opt:
      - no-new-privileges:true
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Pipelines - Advanced routing and filtering (ARM64 compatible)
  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    platform: linux/arm64
    container_name: oracle-pipelines
    restart: always
    user: "1000:1000"  # Non-root user
    ports:
      - "100.96.197.84:9099:9099"
    environment:
      PIPELINES_PORT: 9099
      PIPELINES_OPENAI_API_BASE_URL: http://litellm:4000/v1
      PIPELINES_OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
      # Fix for ARM64 runtime issues
      NODE_ENV: production
      PIP_NO_CACHE_DIR: 1
    volumes:
      - ./pipelines:/app/pipelines:ro
      - pipelines_data:/app/data
    depends_on:
      litellm:
        condition: service_healthy
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9099/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # CPU Inference Server - ARM64 optimized Python service
  cpu-inference:
    image: python:3.11-slim
    platform: linux/arm64
    container_name: oracle-cpu-inference
    restart: always
    user: "1000:1000"  # Non-root user
    ports:
      - "100.96.197.84:8001:8000"
    environment:
      PYTHONUNBUFFERED: 1
      PYTHONDONTWRITEBYTECODE: 1
      PIP_NO_CACHE_DIR: 1
      PYTHONPATH: /app
      MODEL_NAME: microsoft/DialoGPT-small
      DEVICE: cpu
      PORT: 8000
    working_dir: /app
    command: >
      sh -c "
        pip install --no-cache-dir flask transformers torch --quiet &&
        python -c '
        from flask import Flask, request, jsonify
        import torch
        from transformers import AutoModelForCausalLM, AutoTokenizer
        import os
        
        app = Flask(__name__)
        model_name = os.getenv(\"MODEL_NAME\", \"microsoft/DialoGPT-small\")
        device = os.getenv(\"DEVICE\", \"cpu\")
        
        print(f\"Loading model: {model_name} on {device}\")
        try:
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForCausalLM.from_pretrained(model_name)
            model.to(device)
            print(\"Model loaded successfully\")
        except Exception as e:
            print(f\"Model loading failed: {e}\")
            tokenizer = None
            model = None
        
        @app.route(\"/health\", methods=[\"GET\"])
        def health():
            return jsonify({\"status\": \"healthy\", \"device\": device})
        
        @app.route(\"/generate\", methods=[\"POST\"])
        def generate():
            if not model or not tokenizer:
                return jsonify({\"error\": \"Model not loaded\"}), 500
            
            data = request.get_json()
            prompt = data.get(\"prompt\", \"Hello\")
            
            inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)
            outputs = model.generate(**inputs, max_length=50, num_return_sequences=1)
            response = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            return jsonify({\"response\": response})
        
        if __name__ == \"__main__\":
            app.run(host=\"0.0.0.0\", port=int(os.getenv(\"PORT\", 8000)))
        '
      "
    networks:
      - aiswarm
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 3
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

volumes:
postgres_data:
  driver: local
redis_data:
  driver: local
consul_data:
  driver: local
litellm_logs:
  driver: local
open_webui_data:
  driver: local
grafana_data:
  driver: local
prometheus_data:
  driver: local
vault_data:
  driver: local
pipelines_data:
  driver: local
cpu_inference_data:
  driver: local
elasticsearch_data:
  driver: local

networks:
aiswarm:
  driver: bridge
  ipam:
    config:
      - subnet: 172.20.0.0/24