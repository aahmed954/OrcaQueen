# AI-SWARM-MIAMI-2025 Environment Configuration
# Copy this file to .env and fill in your actual values
# NEVER commit the actual .env file to version control

# === SECURITY KEYS (CHANGE ALL DEFAULTS) ===
LITELLM_MASTER_KEY=sk-CHANGE-THIS-TO-SECURE-RANDOM-STRING
POSTGRES_PASSWORD=CHANGE-THIS-TO-SECURE-PASSWORD
REDIS_PASSWORD=CHANGE-THIS-TO-SECURE-PASSWORD
WEBUI_SECRET_KEY=CHANGE-THIS-TO-SECURE-RANDOM-STRING-64-CHARS
ADMIN_PASSWORD=CHANGE-THIS-TO-SECURE-PASSWORD

# === API KEYS ===
# OpenRouter for uncensored models
OPENROUTER_API_KEY=

# Gemini API keys (dual for quota management)
GEMINI_API_KEY=
GEMINI_API_KEY_ALT=

# Google Drive API for 60TB storage
GOOGLE_DRIVE_API_KEY=
GOOGLE_DRIVE_API_KEY_ALT=

# Research tools
TAVILY_API_KEY=
SERP_API_KEY=
GOOGLE_API_KEY=

# HuggingFace for model downloads
HUGGINGFACE_TOKEN=

# === NODE CONFIGURATION ===
# Tailscale IPs (verify these match your actual network)
ORACLE_IP=100.96.197.84
STARLORD_IP=100.72.73.3
THANOS_IP=100.122.12.54

# === SERVICE PORTS ===
# Oracle services
OPEN_WEBUI_PORT=3000
LITELLM_PORT=4000
PIPELINES_PORT=9099

# Starlord services
VLLM_PORT=8000
QDRANT_PORT=6333
GPU_MONITOR_PORT=9091

# Thanos services
SILLYTAVERN_PORT=8080
EXTRAS_PORT=5100
GPT_RESEARCHER_PORT=8001

# === PERFORMANCE SETTINGS ===
# GPU memory utilization (0.0-1.0)
GPU_MEMORY_UTILIZATION=0.85

# Model context lengths
MAX_MODEL_LEN=32768  # Start conservative, increase later

# Batch sizes
MAX_BATCH_TOKENS=8192

# === MONITORING ===
PROMETHEUS_RETENTION=30d
GRAFANA_ADMIN_PASSWORD=CHANGE-THIS-TO-SECURE-PASSWORD

# === EMAIL ACCOUNTS ===
GOOGLE_DRIVE_MAIN=azharahmed954@gmail.com
GOOGLE_DRIVE_SECONDARY=aahmed3688@gmail.com

# === TIMEZONE ===
TZ=America/New_York